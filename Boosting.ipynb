{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost Algorithm\n",
    "\n",
    "* 初始化训练数据的权值分布\n",
    "\n",
    "$$D_1 = (w_{11}, \\cdots, w_{1i}, \\cdots, w_{1N}), \\ w_{1i} = \\frac{1}{N}, \\ i=1, 2, \\cdots, N$$\n",
    "\n",
    "* 对$m = 1,2, \\cdots, M$\n",
    "    \n",
    "    * 使用具有权值分布$D_m$的训练数据集学习，得到基本分类器$G_m(x)$\n",
    "    \n",
    "    * 计算$G_m(x)$在训练数据集上的分类误差率\n",
    "    \n",
    "    $$e_m=\\sum_{i=1}^NP(G_m(x_i)\\neq y_i)=\\sum_{i=1}^Nw_{mi}I(G_m(x_i)\\neq y_i)$$\n",
    "    \n",
    "    * 计算$G_m(x)$的系数\n",
    "    \n",
    "    $$\\alpha_m=\\frac{1}{2}log\\frac{1-e_m}{e_m}$$\n",
    "    \n",
    "    * 更新训练数据集的权值分布\n",
    "    \n",
    "    $$D_{m+1} = (w_{m+1, 1}, \\cdots, w_{m+1, i}, \\cdots, w_{m+1, N})$$\n",
    "    \n",
    "    $$w_{m+1, i}=\\frac{w_{mi}}{Z_m}exp(-\\alpha_my_iG_m(x_i))$$\n",
    "    \n",
    "    $$Z_m = \\sum_{i=1}^Nw_{mi}exp(-\\alpha_my_iG_m(x_i))$$\n",
    "\n",
    "* 得到最终分类器\n",
    "\n",
    "$$G(x)=sign(\\sum_{m=1}^M\\alpha_mG_m(x))$$\n",
    "\n",
    "## Boosting Tree\n",
    "\n",
    "### 梯度提升算法\n",
    "\n",
    "* 初始化\n",
    "\n",
    "$$f_0(x)=argmin_c \\sum_{i=1}^NL(y_i,c)$$\n",
    "\n",
    "* 对$m = 1,2, \\cdots, M$\n",
    "\n",
    "    * 对$i = 1,2, \\cdots, N$，计算\n",
    "    \n",
    "    $$r_{mi}=-[\\frac{\\partial L(y_i, f(x_i))}{\\partial f(x_i)}]_{f(x)=f_{m-1}(x)}$$\n",
    "    \n",
    "    * 对$r_{mi}$拟合一个回归树，得到第m棵树的叶结点区域$R_{mj}, j = 1, 2, \\cdots, J$\n",
    "    \n",
    "    * 对$j = 1, 2, \\cdots, J$，计算\n",
    "    \n",
    "    $$c_{mj}=argmin_c \\sum_{x_i \\in R_{mj}}L(y_i,f_{m-1}(x_i)+c)$$\n",
    "    \n",
    "    * 更新$f_m(x)=f_{m-1}(x)+\\sum_{j=1}^Jc_{mj}I(x \\in R_{mj})$\n",
    "    \n",
    "* 得到回归树\n",
    "\n",
    "$$\\hat{f}(x)=f_M(x)=\\sum_{m=1}^M\\sum_{j=1}^Jc_{mj}I(x \\in R_{mj})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 4) (100,)\n"
     ]
    }
   ],
   "source": [
    "X, y = load_iris(return_X_y=True)\n",
    "X, y = X[:100], y[:100]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaBoost():\n",
    "    def __init__(self, n_estimators=50, learning_rate=1.0):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.alpha = np.zeros((1, n_estimators))\n",
    "        self.index = np.zeros((n_estimators, ), dtype=int)\n",
    "        self.threshold = np.zeros((1, n_estimators))\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "        Input:\n",
    "        - X: of shape(N, D)\n",
    "        - y: of shape(N, )\n",
    "        '''\n",
    "        N, self.D = X.shape\n",
    "        w = np.ones((N, )) / N\n",
    "        \n",
    "        for i in range(self.n_estimators):\n",
    "            alpha, self.alpha[i], self.index[i], self.threshold[i] = self._G(w, X, y)\n",
    "            if alpha == np.inf:\n",
    "                break\n",
    "            w = self._W(alpha, i, X, y, alpha)\n",
    "    \n",
    "    def _G(self, w, X, y):\n",
    "        best_error = np.inf\n",
    "        for i in range(self.D):\n",
    "            x = X[:, i]\n",
    "            lower, upper = np.min(x), np.max(x)\n",
    "            j = lower\n",
    "            while j < upper+self.learning_rate:\n",
    "                error_left = np.sum(w * ((x > j) != y))\n",
    "                error_right = np.sum(w * ((x <= j) != y))\n",
    "                \n",
    "                if error_left <= error_right:\n",
    "                    d = 1\n",
    "                    error = error_left\n",
    "                else:\n",
    "                    d = -1\n",
    "                    error = error_right\n",
    "                \n",
    "                if error == 0:\n",
    "                    return np.inf, d * np.inf, i, j\n",
    "                \n",
    "                if error < best_error:\n",
    "                    index = i\n",
    "                    direction = d\n",
    "                    threshold = j\n",
    "                    alpha = np.log((1-error)/error)\n",
    "                    best_error = error\n",
    "                \n",
    "                j += self.learning_rate\n",
    "                \n",
    "        return alpha, alpha * direction, index, threshold\n",
    "    \n",
    "    def _W(self, i, w, X, y):\n",
    "        z = w * np.exp(y * (X[:, i] > self.threshold[i]) * self.alpha[i])\n",
    "        return z / np.sum(z)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.sum((X[:, self.index] > self.threshold) * self.alpha, axis=1) >= 0\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        y_hat = self.predict(X)\n",
    "        return np.sum(y_hat == y) / y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\msi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:60: RuntimeWarning: invalid value encountered in multiply\n",
      "c:\\users\\msi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:60: RuntimeWarning: invalid value encountered in greater_equal\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "adaboost = AdaBoostClassifier()\n",
    "model = AdaBoost()\n",
    "adaboost.fit(X_train, y_train)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(model.score(X_test, y_test), adaboost.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
