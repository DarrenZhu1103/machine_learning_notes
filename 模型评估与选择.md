## 评估方法

### 留出法

&emsp; 留出法直接将数据集$D$划分为两个互斥的集合，其中一个集合作为训练集$S$，另一个作为测试集$T$，即$D=S\bigcup T, S\bigcap T=\emptyset$。在$S$上训练出模型后，用$T$来评估其测试误差，作为对泛化误差的估计，需注意的是，训练集与测试集的划分要尽可能地保持数据分布的一致性。

&emsp; 单次使用留出法的估计结果往往不够稳定可靠，在使用留出法时，一般要采用若干次随即划分、重复进行实验评估后取平均值作为留出法的评估结果。

### 交叉验证法

&emsp; 交叉验证法先将数据集$D$划分为$k$个大小相似的互斥子集，即$D=D_1\bigcup D_2 \bigcup\cdots \bigcup D_k,\ D_i\bigcap D_j = \emptyset(i\neq j)$，每个子集$D_i$都尽可能保持数据分布的一致性。每次用$k-1$个子集的并集作为训练集，从而可进行$k$次训练和测试，最终返回的时这$k$个测试结果的均值。

### 自助法

&emsp; 给定包含$m$个样本的数据集$D$，对其进行采样生成数据集$D'$：每次随机从$D$中挑选一个样本将其拷贝放入$D'$，然后再将该样本放回初始数据集$D$中，使得该样本在下次采样时仍有可能被采到；这个过程重复执行$m$次后，我们就得到了包含$m$个样本的数据集$D'$。样本在$m$次采样中始终不被采到的概率是 $(1-\frac{1}{m})^m$，取极限得：
$$\lim_{m \to +\infty}(1-\frac{1}{m})^m=\frac{1}{e}\approx 0.368$$
即通过自助采样，初始数据集$D$中约有38.6%的样本出现在采样数据集$D'$中。可将$D'$作为训练集，$D$作为测试集。

&emsp; 自助法在数据集较小、难以有效划分训练集和测试集时很有用，并且能从初始数据集中产生多个不同的训练集，对集成学习等方法有很大的好处；但自助法产生的数据集改变了初始数据集的分布，这回引入估计偏差，所以在初始数据量足够时，留出法和交叉验证法更为常用

## 性能度量

### 错误率与精度

&emsp; 错误率和精度是分类任务中最常用的两种性能度量，错误率是分类错误的样本数占样本总数的比例，精度则是分类正确的样本数占样本总数的比例。

$$E(f; D) = \frac{1}{m}\sum_{i=1}^mI(f(x_i) \neq y_i)$$

$$acc(f; D) = \frac{1}{m}\sum_{i=1}^mI(f(x_i) = y_i) = 1 - E(f; D)$$

### 查全率、查准率、$F1$

&emsp; 对二分类问题，可将样例根据其真实类别与学习器预测类别的组合分为真正例(true positive)、假正例(false positive)、真反例(true negative)、假反例(false negative)四种情形。


<html>
<table>
   <tr>
      <td rowspan="2">真实情况</td>
      <td colspan="2">预测结果</td>
   </tr>
   <tr>
      <td>真</td>
      <td>假</td>
   </tr>
   <tr>
      <td>真</td>
      <td>TP（真正例）</td>
      <td>FN（假反例）</td>
   </tr>
   <tr>
      <td>假</td>
      <td>FP（假正例）</td>
      <td>TN（真反例）</td>
   </tr>
</table>

&emsp; 查准率P与查全率R分别定义为：

$$P=\frac{TP}{TP+FP}$$

$$R=\frac{TP}{TP+FN}$$

I&emsp; 查准率和查全率是一对矛盾的度量。一般来说，查准率高时，查全率往往偏低；而查全率高时，查准率往往偏低。在很多情形下，我们可根据学习器的预测结果对样例进行排序，排在前面的是学习器认为“最可能”是正例的样本，排在最后的则是学习器认为“最不可能”是正例的样本。按此顺序逐个把样本作为正例进行预测，则可以每次计算出当前的查全率、查准率。以查准率为纵轴、查全率作为横轴作图，就可以得到查全率-查准率曲线，简称“P-R曲线”。在进行比较时，若一个学习器的P-R曲线能被另一个学习器的曲线完全包住，则可断言后者的性能优于前者；若两个学习器的曲线发生了交叉，则一般难以断言两者优劣，“平衡点”(BEP)是一个综合考虑查准率、查全率的度量，它是查准率与查全率相等时的取值，但BEP还是过于简化了些，更常用的是$F1$度量：

$$F1=\frac{2\times P \times R}{P+R}=\frac{2\times TP}{样例总数+TP-TN}$$

&emsp; 在一些应用中，对查准率和查全率的重视程度有所不同，例如在商品推荐系统中，为了尽可能少打扰用户，更希望推荐内容确实是用户感兴趣的，此时查准率就比较重要。$F1$度量的一般形式$F_{\beta}$，可以表达对查全率与查准率的不同偏好：

$$F_{\beta}=\frac{(1+\beta^2)\times P \times R}{(\beta^2\times P)+R}$$

&emsp; 其中$\beta$度量了查全率对对查准率的相对重要性，$\beta=1$时退化为标准的$F1$；$\beta>1$时查全率有更大影响；$\beta<1$时查准率有更大影响。
