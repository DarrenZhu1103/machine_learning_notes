{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 评估方法\n",
    "\n",
    "### 留出法\n",
    "\n",
    "&emsp; 留出法直接将数据集$D$划分为两个互斥的集合，其中一个集合作为训练集$S$，另一个作为测试集$T$，即$D=S\\bigcup T, S\\bigcap T=\\emptyset$。在$S$上训练出模型后，用$T$来评估其测试误差，作为对泛化误差的估计，需注意的是，训练集与测试集的划分要尽可能地保持数据分布的一致性。\n",
    "\n",
    "&emsp; 单次使用留出法的估计结果往往不够稳定可靠，在使用留出法时，一般要采用若干次随即划分、重复进行实验评估后取平均值作为留出法的评估结果。\n",
    "\n",
    "### 交叉验证法\n",
    "\n",
    "&emsp; 交叉验证法先将数据集$D$划分为$k$个大小相似的互斥子集，即$D=D_1\\bigcup D_2 \\bigcup\\cdots \\bigcup D_k,\\ D_i\\bigcap D_j = \\emptyset(i\\neq j)$，每个子集$D_i$都尽可能保持数据分布的一致性。每次用$k-1$个子集的并集作为训练集，从而可进行$k$次训练和测试，最终返回的时这$k$个测试结果的均值。\n",
    "\n",
    "### 自助法\n",
    "\n",
    "&emsp; 给定包含$m$个样本的数据集$D$，对其进行采样生成数据集$D'$：每次随机从$D$中挑选一个样本将其拷贝放入$D'$，然后再将该样本放回初始数据集$D$中，使得该样本在下次采样时仍有可能被采到；这个过程重复执行$m$次后，我们就得到了包含$m$个样本的数据集$D'$。样本在$m$次采样中始终不被采到的概率是 $(1-\\frac{1}{m})^m$，取极限得：\n",
    "$$\\lim_{m \\to +\\infty}(1-\\frac{1}{m})^m=\\frac{1}{e}\\approx 0.368$$\n",
    "即通过自助采样，初始数据集$D$中约有38.6%的样本出现在采样数据集$D'$中。可将$D'$作为训练集，$D$作为测试集。\n",
    "\n",
    "&emsp; 自助法在数据集较小、难以有效划分训练集和测试集时很有用，并且能从初始数据集中产生多个不同的训练集，对集成学习等方法有很大的好处；但自助法产生的数据集改变了初始数据集的分布，这回引入估计偏差，所以在初始数据量足够时，留出法和交叉验证法更为常用\n",
    "\n",
    "## 性能度量\n",
    "\n",
    "### 错误率与精度\n",
    "\n",
    "&emsp; 错误率和精度是分类任务中最常用的两种性能度量，错误率是分类错误的样本数占样本总数的比例，精度则是分类正确的样本数占样本总数的比例。\n",
    "\n",
    "$$E(f; D) = \\frac{1}{m}\\sum_{i=1}^mI(f(x_i) \\neq y_i)$$\n",
    "\n",
    "$$acc(f; D) = \\frac{1}{m}\\sum_{i=1}^mI(f(x_i) = y_i) = 1 - E(f; D)$$\n",
    "\n",
    "### 查全率、查准率、$F1$\n",
    "\n",
    "&emsp; 对二分类问题，可将样例根据其真实类别与学习器预测类别的组合分为真正例(true positive)、假正例(false positive)、真反例(true negative)、假反例(false negative)四种情形。\n",
    "\n",
    "\n",
    "<html>\n",
    "<table>\n",
    "   <tr>\n",
    "      <td rowspan=\"2\">真实情况</td>\n",
    "      <td colspan=\"2\">预测结果</td>\n",
    "   </tr>\n",
    "   <tr>\n",
    "      <td>真</td>\n",
    "      <td>假</td>\n",
    "   </tr>\n",
    "   <tr>\n",
    "      <td>真</td>\n",
    "      <td>TP（真正例）</td>\n",
    "      <td>FN（假反例）</td>\n",
    "   </tr>\n",
    "   <tr>\n",
    "      <td>假</td>\n",
    "      <td>FP（假正例）</td>\n",
    "      <td>TN（真反例）</td>\n",
    "   </tr>\n",
    "</table>\n",
    "\n",
    "&emsp; 查准率P与查全率R分别定义为：\n",
    "\n",
    "$$P=\\frac{TP}{TP+FP}$$\n",
    "\n",
    "$$R=\\frac{TP}{TP+FN}$$\n",
    "\n",
    "&emsp; 查准率和查全率是一对矛盾的度量。一般来说，查准率高时，查全率往往偏低；而查全率高时，查准率往往偏低。在很多情形下，我们可根据学习器的预测结果对样例进行排序，排在前面的是学习器认为“最可能”是正例的样本，排在最后的则是学习器认为“最不可能”是正例的样本。按此顺序逐个把样本作为正例进行预测，则可以每次计算出当前的查全率、查准率。以查准率为纵轴、查全率作为横轴作图，就可以得到查全率-查准率曲线，简称“P-R曲线”。在进行比较时，若一个学习器的P-R曲线能被另一个学习器的曲线完全包住，则可断言后者的性能优于前者；若两个学习器的曲线发生了交叉，则一般难以断言两者优劣，“平衡点”(BEP)是一个综合考虑查准率、查全率的度量，它是查准率与查全率相等时的取值，但BEP还是过于简化了些，更常用的是$F1$度量：\n",
    "\n",
    "$$F1=\\frac{2\\times P \\times R}{P+R}=\\frac{2\\times TP}{样例总数+TP-TN}$$\n",
    "\n",
    "&emsp; 在一些应用中，对查准率和查全率的重视程度有所不同，例如在商品推荐系统中，为了尽可能少打扰用户，更希望推荐内容确实是用户感兴趣的，此时查准率就比较重要。$F1$度量的一般形式$F_{\\beta}$，可以表达对查全率与查准率的不同偏好：\n",
    "\n",
    "$$F_{\\beta}=\\frac{(1+\\beta^2)\\times P \\times R}{(\\beta^2\\times P)+R}$$\n",
    "\n",
    "&emsp; 其中$\\beta$度量了查全率对对查准率的相对重要性，$\\beta=1$时退化为标准的$F1$；$\\beta>1$时查全率有更大影响；$\\beta<1$时查准率有更大影响。\n",
    "\n",
    "### $ROC$与$AUC$\n",
    "\n",
    "&emsp; $ROC$的全称时Receiver Operating Characteristic，与$P-R$曲线十分类似，我们可根据学习器的预测结果对样例进行排序，按此顺序逐个把样本作为正例进行预测，$ROC$曲线的纵轴是真正例率(TPR)，横轴是假正例率(FPR)：\n",
    "\n",
    "$$TPR=\\frac{TP}{TP+FN}$$\n",
    "\n",
    "$$FPR=\\frac{FP}{TN+FP}$$\n",
    "\n",
    "&emsp; 现实任务中通常是利用有限个测试样例来绘制$ROC$图，此时仅能获得有限个坐标对。给定$m^+$个正例和$m^-$个负例，我们可根据学习器的预测结果对样例进行排序，首先将所有测试样例预测为反例，然后依次增加分类阈值增加一个预测正例，最后将所有相邻点连接即可。\n",
    "\n",
    "&emsp; 进行学习器比较时，若一个学习器的$ROC$曲线能被另一个学习器的曲线完全包住，则可断言后者的性能优于前者。若两个学习器的$ROC$曲线发生了交叉，则可比较曲线下的面积，即$AUC$(Area Under ROC Curve)。\n",
    "\n",
    "### 代价敏感错误率与代价曲线\n",
    "\n",
    "<html>\n",
    "<table>\n",
    "   <tr>\n",
    "      <td rowspan=\"2\">真实类别</td>\n",
    "      <td colspan=\"2\">预测类别</td>\n",
    "   </tr>\n",
    "   <tr>\n",
    "      <td>0</td>\n",
    "      <td>1</td>\n",
    "   </tr>\n",
    "   <tr>\n",
    "      <td>0</td>\n",
    "      <td>0</td>\n",
    "      <td>$cost_{01}$</td>\n",
    "   </tr>\n",
    "   <tr>\n",
    "      <td>1</td>\n",
    "      <td>$cost_{10}$</td>\n",
    "      <td>0</td>\n",
    "   </tr>\n",
    "</table>\n",
    "\n",
    "&emsp; 在非均等代价下，$ROC$曲线不能直接反应出学习器的期望总体代价，而通过“代价曲线”则可达到该目的，代价曲线的横轴时正例概率代价\n",
    "\n",
    "$$P(+)cost=\\frac{p\\times cost_{01}}{p\\times cost_{01} + (1-p)\\times cost_{10}}$$\n",
    "\n",
    "其中$p$时样例为正例的概率；纵轴是归一化代价\n",
    "\n",
    "$$cost_{norm}=\\frac{FNR\\times p\\times cost_{01} + FPR\\times (1-p)\\times cost_(10)}{p\\times cost_{01} + (1-p)\\times cost_{10}}$$\n",
    "\n",
    "$$FNR=1-TPR$$\n",
    "\n",
    "&emsp; $ROC$曲线上的没一点对应了代价平面上的一条线段，线段下的面积代表了该条件下的期望总体代价；如此将$ROC$曲线上的每个段转化为代价平面上的一条线段，然后取所有线段的下届，围成的面积即为在所有条件下学习器的期望总体代价。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
