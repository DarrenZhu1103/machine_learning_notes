{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hidden Markov Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HMM模型\n",
    "\n",
    "&emsp; 隐马尔可夫模型使关于时序的概率模型，描述一个隐藏的马尔科夫链随机生成不可观测的状态随机序列，再由各个状态生成一个观测而产生观测随机序列的过程。隐藏的马尔可夫链随机生成的状态序列被称为状态序列；每个状态生成一个观测，由此产生的观测的随机序列，称为观测序列。序列的每个位置可看作一个时刻。\n",
    "\n",
    "&emsp; 设Q是所有可能的状态的集合，N是可能的状态数；V是所有可能观测的集合，M是可能的观测数。\n",
    "\n",
    "$$Q={q_1, q_2, \\cdots, q_N},\\ \\ V={v_1, v_2, \\cdots, v_M}$$\n",
    "\n",
    "&emsp; I是长度为T的状态序列，O是对应的观测序列\n",
    "\n",
    "$$I=(i_1, i_2, \\cdots, i_T),\\ \\ O=(o_1, o_2, \\cdots, o_T)$$\n",
    "\n",
    "&emsp; A是状态转移概率矩阵：\n",
    "\n",
    "$$A=[a_{ij}]_{N \\times N}, a_{ij} = P(i_{t+1}=q_j|i_t=q_i)$$\n",
    "\n",
    "&emsp; B是观测概率矩阵：\n",
    "\n",
    "$$B=[b_j(k)]_{N \\times M}, b_j(k) = P(o_t=v_k|i_t=q_j)$$\n",
    "\n",
    "&emsp; $\\pi$是初始状态概率向量：\n",
    "\n",
    "$$\\pi=(\\pi_i), \\pi_i=P(i_1=q_i)$$\n",
    "\n",
    "&emsp; 隐马尔可夫模型$\\lambda$可以用三元符号表示：\n",
    "\n",
    "$$\\lambda=(A, B, \\pi)$$\n",
    "\n",
    "&emsp; 隐马尔可夫模型作了两个基本假设\n",
    "\n",
    "* 齐次马尔可夫性假设，即假设隐藏的马尔可夫链在任意时刻t的状态只依赖于其前一刻的状态，与其他时刻的状态及观测无关，也与时刻t无关\n",
    "\n",
    "$$P(i_t|i_{t-1}, o_{t-1}, \\cdots, i_1, o_1)=P(i_t|i_{t-1})$$\n",
    "\n",
    "* 观测独立性假设，即假设任意时刻的观测只依赖于该时刻的马尔可夫链的状态，与其他观测及状态无关\n",
    "\n",
    "$$P(o_t|i_T, o_T, i_{T-1}, o_{T-1}, \\cdots, i_{t+1}, o_{t+1}, i_t, i_{t-1}, o_{t-1},\\cdots, i_1, o_1)=P(o_t|i_t)$$\n",
    "\n",
    "## 概率计算\n",
    "\n",
    "### 直接计算法\n",
    "\n",
    "&emsp; 对所有可能的状态序列I求和，的到观测序列O的概率$P(O|\\lambda)$，该算法复杂度$O(TN^T)$，不可行\n",
    "\n",
    "$$P(O|\\lambda)=\\sum_IP(O|I, \\lambda)P(I|\\lambda)=\\sum_{i_1, i_2, \\cdots, i_T}\\pi_{i_1}b_{i_1}(o_1)a_{i_1i_2}b_{i_2}(o_2)\\cdots a_{i_{T-1}i_T}b_{i_T}(o_T)$$\n",
    "\n",
    "### 前向算法\n",
    "\n",
    "#### 前向概率\n",
    "\n",
    "&emsp; 给定隐马尔可夫模型$\\lambda$，定义到时刻t部分观测序列为$o_1, o_2, \\cdots, o_t$且状态为$q_i$的概率为前向概率，记作\n",
    "\n",
    "$$\\alpha_t(i)=P(o_1, o_2, \\cdots, o_t, i_t=q_i|\\lambda)$$\n",
    "\n",
    "#### 观测序列概率的前向算法\n",
    "\n",
    "* 初值\n",
    "\n",
    "$$\\alpha_1(i)=\\pi_ib_i(o_1)$$\n",
    "\n",
    "* 递推 对$t=1,2,\\cdots T-1$\n",
    "\n",
    "$$\\alpha_{t+1}(i)=[\\sum_{j=1}^N\\alpha_t(j)a_{ji}]b_i(o_{t+1})$$\n",
    "\n",
    "* 终止\n",
    "\n",
    "$$P(O|\\lambda)=\\sum_{j=1}^N\\alpha_T(i)$$\n",
    "\n",
    "&emsp; 计算量为$O(TN^2)$\n",
    "\n",
    "### 后向算法\n",
    "\n",
    "#### 后向概率\n",
    "\n",
    "&emsp; 给定隐马尔可夫模型$\\lambda$，定义到时刻t状态为$q_i$的条件下，从$t+1$到T的部分观测序列为$o_{t+1}, o_{t+2}, \\cdots, o_T$的概率为后向概率，记作\n",
    "\n",
    "$$\\beta_t(i)=P(o_{t+1}, o_{t+2}, \\cdots, o_T|i_t=q_i, \\lambda)$$\n",
    "\n",
    "#### 观测序列概率的后向算法\n",
    "\n",
    "* 首先\n",
    "\n",
    "$$\\beta_T(i)=1$$\n",
    "\n",
    "* 递推 对$t=T-1,T-2,\\cdots 1$\n",
    "\n",
    "$$\\beta_t(i)=\\sum_{j=1}^Na_{ij}b_j(o_{t+1})\\beta_{t+1}(j)$$\n",
    "\n",
    "* 终止\n",
    "\n",
    "$$P(O|\\lambda)=\\sum_{j=1}^N\\pi_ib_i(o_1)\\beta_1(i)$$\n",
    "\n",
    "#### 一些概率和期望计算\n",
    "\n",
    "* 给定模型$\\lambda$和观测$O$，在时刻$t$处处于状态$q_i$的概率\n",
    "\n",
    "$$\\gamma_t(i)=\\frac{\\alpha_t(i)\\beta_t(i)}{\\sum_{j=1}^N\\alpha_t(j)\\beta_t(j)}$$\n",
    "\n",
    "* 给定模型$\\lambda$和观测$O$，在时刻$t$处处于状态$q_i$且在时刻$t+1$处处于状态$q_j$的概率\n",
    "\n",
    "$$\\xi_t(i, j)=\\frac{\\alpha_t(i)a_{ij}b_j(o_{t+1})\\beta_{t+1}(j)}{\\sum_{i=1}^N\\sum_{j=1}^N\\alpha_t(i)a_{ij}b_j(o_{t+1})\\beta_{t+1}(j)}$$\n",
    "\n",
    "* 在观测$O$下状态$i$出现的期望值\n",
    "\n",
    "$$\\sum_{t=1}^T\\gamma_t(i)$$\n",
    "\n",
    "* 在观测$O$下由状态$i$转移到状态$j$的期望值\n",
    "\n",
    "$$\\sum_{t=1}^{T-1}\\xi_t(i, j)$$\n",
    "\n",
    "## 学习算法\n",
    "\n",
    "&emsp; 隐马尔可夫模型的学习问题是根据已知观测序列，估计模型参数，采用极大似然估计的方法。\n",
    "\n",
    "#### Baum-Welch算法\n",
    "\n",
    "&emsp; 假定训练数据只包含S个长度为T的观测序列${O_1, O_2, \\cdots, O_S}$而没有对应的状态序列，目标是学习隐马尔可夫模型$\\lambda=(A, B, \\pi)$的参数。将观测序列数据看作观测数据$O$，状态序列数据看作不可观测的隐数据$I$，那么隐马尔可夫模型实际上是一个含有隐变量的概率模型$P(O|\\lambda)=\\sum_IP(O|I, \\lambda)P(I|\\lambda)$，参数学习可由EM算法实现。\n",
    "\n",
    "* 初始化\n",
    "\n",
    "&emsp; 对$n=0$，选取$a_{ij}^{(0)}, b_j(k)^{(0)},\\pi_i^{(0)}$，得到模型$\\lambda^{(0)}=(A^{(0)}, B^{(0)}, \\pi^{(0)})$\n",
    "\n",
    "* 递推，对$n=1,2, \\cdots ,$\n",
    "\n",
    "$$a_{ij}^{(n+1)}=\\frac{\\sum_{t=1}^{T-1}\\xi_t(i, j)}{\\sum_{t=1}^{T-1}\\gamma_t(i)}$$\n",
    "\n",
    "$$b_j(k)^{(n+1)}=\\frac{\\sum_{t=1,o_t=v_k}^T\\gamma_t(j)}{\\sum_{t=1}^T\\gamma_t(j)}$$\n",
    "\n",
    "$$\\pi_i^{(n+1)}=\\gamma_1(i)$$\n",
    "\n",
    "## 预测算法\n",
    "\n",
    "&emsp; 也成为解码问题，已知模型和观测序列，求最有可能对应的状态序列\n",
    "\n",
    "### 近似算法\n",
    "\n",
    "$$i_t=argmax_i[\\gamma_t(i)]$$\n",
    "\n",
    "&emsp; 近似算法的优点是计算简单，缺点是不能保证预测的状态序列整体是最有可能的序列状态，因为预测的状态序列可能有实际不发生的部分。\n",
    "\n",
    "### 维特比算法\n",
    "\n",
    "&emsp; 维特比算法实际是用动态规划解隐马尔可夫模型预测问题，即用动态规划求概率最大路径，此时一条路径对应一个状态序列。\n",
    "\n",
    "&emsp; 定义在时刻t状态为i的所有单个路径$(i_1, i_2, \\cdots, i_{t-1}, i)$中概率最大值为\n",
    "\n",
    "$$\\delta_t(i)=max_{i_1, i_2, \\cdots, i_{t-1}}P(i_t=t,i_{t-1}, \\cdots, i_1, o_t, \\cdots, o_1|\\lambda)$$\n",
    "\n",
    "&emsp; 由定义可得递推公式：\n",
    "\n",
    "$$\\delta_{t+1}(i)=max_{1\\leq j\\leq N}[\\delta_t(j)a_{ji}]b_i(o_{t+1})$$\n",
    "\n",
    "&emsp; 定义在时刻t状态为i的所有单个路径$(i_1, i_2, \\cdots, i_{t-1}, i)$中概率最大的路径的第$t-1$个结点为\n",
    "\n",
    "$$\\psi_t(i)=argmax_{1\\leq j\\leq N}[\\delta_{t-1}(j)a_{ji}]$$\n",
    "\n",
    "&emsp; 维特比算法\n",
    "\n",
    "* 初始化\n",
    "\n",
    "$$\\delta_1(i)=\\pi_ib_i(o_1)$$\n",
    "\n",
    "$$\\psi_1(i)=0$$\n",
    "\n",
    "* 递推，对$t=2,3,\\cdots,T$\n",
    "\n",
    "$$\\delta_t(i)=max_{1\\leq j\\leq N}[\\delta_{t-1}(j)a_{ji}]b_i(o_t)$$\n",
    "\n",
    "$$\\psi_t(i)=argmax_{1\\leq j\\leq N}[\\delta_{t-1}(j)a_{ji}]$$\n",
    "\n",
    "* 终止\n",
    "\n",
    "$$P=max_{1\\leq j\\leq N}\\delta_T(i)$$\n",
    "\n",
    "$$i_T=argmax_{1\\leq j\\leq N}[\\delta_T(i)]$$\n",
    "\n",
    "* 最优路径回溯，对$t=T-1,T-2,\\cdots,1$\n",
    "\n",
    "$$i_t=\\psi_{t+1}(i_{t+1})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiddenMarkovModel():\n",
    "    def __init__(self, num_of_states, num_of_observation, times, A=None, B=None, pi=None, max_iter=200):\n",
    "        if A is None:\n",
    "            self.A = np.ones((num_of_states, num_of_states)) / num_of_states\n",
    "        else:\n",
    "            self.A = A\n",
    "        if B is None:\n",
    "            self.B = np.ones((num_of_states, num_of_observation)) / num_of_observation\n",
    "        else:\n",
    "            self.B = B\n",
    "        if pi is None:\n",
    "            self.pi = np.ones((num_of_states, )) / num_of_states\n",
    "        else:\n",
    "            self.pi = pi\n",
    "        self.num_of_states = num_of_states\n",
    "        self.num_of_observation = num_of_observation\n",
    "        self.times = times\n",
    "        self.max_iter = max_iter\n",
    "    \n",
    "    def fit(self, observations):\n",
    "        over = False\n",
    "        for i in range(self.max_iter):\n",
    "            _, alpha = self.forward(observations)\n",
    "            _, beta = self.backward(observations)\n",
    "            z = alpha[:-1].reshape(self.times-1, self.num_of_states, 1) * self.A.reshape(1, self.num_of_states, self.num_of_states) * self.B[:, observations[1:]].T.reshape(self.times-1, 1, self.num_of_states) * beta[1:].reshape(self.times-1, 1, self.num_of_states)\n",
    "            xi = z / np.sum(z, axis=(1, 2), keepdims=True)\n",
    "            gamma = alpha * beta / np.sum(alpha * beta, axis=1, keepdims=True)\n",
    "            #gamma = np.sum(xi,axis=2)\n",
    "            #prod =  (alpha[-1,:] * beta[-1,:]).reshape((1, -1))\n",
    "            #gamma = np.vstack((gamma,  prod / np.sum(prod)))\n",
    "            # phi shape of (#times-1, #states, #states), gamma shape of (#times, #states)\n",
    "            A = np.divide(np.sum(xi, axis=0), np.sum(gamma[:-1], axis=0).reshape(-1, 1))\n",
    "            one_hot = np.eye(np.max(observations)+1)[observations]\n",
    "            B = np.dot(gamma.T, one_hot) / np.sum(gamma, axis=0).reshape(-1, 1)\n",
    "            pi = gamma[0]\n",
    "            over = np.max(self.A-A) < 0.05 and np.max(self.B-B) < 0.05 and np.max(self.pi-pi) < 0.05\n",
    "            self.A = A\n",
    "            self.B = B\n",
    "            self.pi = pi\n",
    "            if over:\n",
    "                break\n",
    "    \n",
    "    def forward(self, observations):\n",
    "        alpha = np.zeros((self.times, self.num_of_states))\n",
    "        for i in range(self.num_of_states):\n",
    "            alpha[0][i] = self.pi[i] * self.B[i][observations[0]]\n",
    "        for i in range(1, self.times):\n",
    "            obs = observations[i]\n",
    "            for j in range(self.num_of_states):\n",
    "                alpha[i][j] = np.sum(alpha[i-1, :]*self.A[:, j]) * self.B[j][obs]\n",
    "        P = np.sum(alpha[self.times-1])\n",
    "        return P, alpha\n",
    "    \n",
    "    def backward(self, observations):\n",
    "        beta = np.ones((self.times, self.num_of_states))\n",
    "        for i in range(self.times-2, -1, -1):\n",
    "            obs = observations[i+1]\n",
    "            for j in range(self.num_of_states):\n",
    "                beta[i][j] = np.sum(beta[i+1, :]*self.A[j, :]*self.B[:, obs])\n",
    "        P = np.sum(self.pi*beta[0]*self.B[:, observations[0]])\n",
    "        return P, beta\n",
    "    \n",
    "    def decode(self, observations):\n",
    "        prob = np.zeros((self.times, self.num_of_states))\n",
    "        path = np.zeros((self.times-1, self.num_of_states), dtype=int)\n",
    "        prob[0] = self.pi * self.B[:, observations[0]]\n",
    "        for i in range(1, self.times):\n",
    "            z = prob[i-1].reshape(-1, 1) * self.A\n",
    "            prob[i] = np.max(z, axis=0) * self.B[:, observations[i]]\n",
    "            path[i-1] = np.argmax(z, axis=0)\n",
    "        P = np.max(prob[-1])\n",
    "        state = np.argmax(prob[-1])\n",
    "        result = np.zeros((self.times, ))\n",
    "        result[-1] = state\n",
    "        for i in range(self.times-2, -1, -1):\n",
    "            state = path[i, state]\n",
    "            result[i] = state\n",
    "        return P, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.130218, array([[0.1     , 0.16    , 0.28    ],\n",
      "       [0.077   , 0.1104  , 0.0606  ],\n",
      "       [0.04187 , 0.035512, 0.052836]]))\n",
      "(0.014699999999999998, array([2., 2., 2.]))\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[0.5, 0.2, 0.3], [0.3, 0.5, 0.2], [0.2, 0.3, 0.5]])\n",
    "B = np.array([[0.5, 0.5], [0.4, 0.6], [0.7, 0.3]])\n",
    "pi = np.array([0.2, 0.4, 0.4])\n",
    "observations_1 = np.array([0, 1, 0])\n",
    "test_model = HiddenMarkovModel(3, 2, 3, A, B, pi)\n",
    "print(test_model.forward(observations_1))\n",
    "print(test_model.decode(observations_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0030239999999999993, array([2., 1., 1., 1.]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[0.5, 0.2, 0.3], [0.3, 0.5, 0.2], [0.2, 0.3, 0.5]])\n",
    "B = np.array([[0.5, 0.5], [0.4, 0.6], [0.7, 0.3]])\n",
    "pi = np.array([0.2, 0.4, 0.4])\n",
    "observations_2 = np.array([0, 1, 0, 1])\n",
    "test_model = HiddenMarkovModel(3, 2, 4, A, B, pi)\n",
    "test_model.decode(observations_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.33333333 0.33333333 0.33333333]\n",
      " [0.33333333 0.33333333 0.33333333]\n",
      " [0.33333333 0.33333333 0.33333333]] [[0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]] [0.33333333 0.33333333 0.33333333]\n",
      "[[0.33333333 0.33333333 0.33333333]\n",
      " [0.33333333 0.33333333 0.33333333]\n",
      " [0.33333333 0.33333333 0.33333333]] [[0.5 0.5]\n",
      " [0.5 0.5]\n",
      " [0.5 0.5]] [0.33333333 0.33333333 0.33333333]\n"
     ]
    }
   ],
   "source": [
    "model = HiddenMarkovModel(3,2,4)\n",
    "print(model.A, model.B, model.pi)\n",
    "model.fit(observations_2)\n",
    "print(model.A, model.B, model.pi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
